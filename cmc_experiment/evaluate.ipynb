{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import random\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KDTree\n",
    "from openslide import OpenSlide\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# GPU use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
    "\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_SIZE = 2048\n",
    "OVERLAP = 64\n",
    "GAUSS_STD = 10\n",
    "BATCH_SIZE = 4\n",
    "WEIGHT_PATH = \"h5/train_gauss/unet.h5\"\n",
    "test_wsi_ids = [3, 10, 14, 15, 18, 21, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB = sqlite3.connect(\"MITOS_WSI_CMC/databases/MITOS_WSI_CMC_CODAEL_TR_ROI.sqlite\")\n",
    "    \n",
    "file_df = pd.read_sql(\"SELECT * FROM Slides\", DB)\n",
    "label_df = pd.read_sql(\"SELECT * FROM Annotations\", DB)\n",
    "mitosis_df = label_df[label_df[\"agreedClass\"]==2]\n",
    "notmitosis_df = label_df[label_df[\"agreedClass\"]==1]\n",
    "coordinates_df = pd.read_sql(\"SELECT * FROM Annotations_coordinates\", DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide WSI into ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_crop_image(wsi_path, wsi_id, crop_size=CROP_SIZE, overlap=OVERLAP, glass_region_th=200):\n",
    "    \"\"\"\n",
    "    Crop and save images from WSI.\n",
    "    Path of the cropped image.\n",
    "        crop_image/{crop_size}_{overlap}/{wsi_id}/{left top x of WSI}_{left top y of WSI}.png\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    wsi_path : str\n",
    "    wsi_id : int\n",
    "    crop_size : int\n",
    "        Image size of the cropped images.\n",
    "    overlap : int\n",
    "        Number of pixels that overlap with adjacent cropped images.\n",
    "    glass_region_th : int (default : 200)\n",
    "        Threshold to determine the glass part of the slide.\n",
    "        The area judged as the glass part is not saved.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Nothing.\n",
    "    \"\"\"   \n",
    "    wsi = OpenSlide(wsi_path)\n",
    "    wsi_w, wsi_h = wsi.dimensions\n",
    "    level = wsi.level_count\n",
    "    zoom = wsi.level_downsamples[level-1]\n",
    "    save_dir = \"crop_image/{}_{}/{}\".format(crop_size, overlap, wsi_id)\n",
    "    \n",
    "    if os.path.exists(save_dir):\n",
    "        shutil.rmtree(save_dir)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    iter_h = wsi_h//(crop_size-overlap)\n",
    "    iter_w = wsi_w//(crop_size-overlap)\n",
    "    for i in range(iter_h):\n",
    "        for j in range(iter_w):\n",
    "            location = (j*(crop_size-overlap), i*(crop_size-overlap))\n",
    "            roi = wsi.read_region(location, level-1, (int(crop_size/zoom), int(crop_size/zoom)))\n",
    "            if np.min(np.array(roi.convert(\"L\")))<glass_region_th:\n",
    "                img = wsi.read_region(location, 0, (crop_size, crop_size))\n",
    "                img.save(\"{}/{}_{}.png\".format(save_dir, location[0], location[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slide_list = glob.glob(\"MITOS_WSI_CMC/WSI/*.svs\")\n",
    "\n",
    "zip_list = []\n",
    "for slide_path in slide_list:\n",
    "    filename = slide_path.split(\"/\")[-1]\n",
    "    filedata = file_df[file_df[\"filename\"]==filename]\n",
    "    wsi_id = filedata.iat[0, 0]\n",
    "    zip_list.append([slide_path, wsi_id])\n",
    "\n",
    "# To give multiple arguments\n",
    "def wrapper(args):\n",
    "    return save_crop_image(*args) \n",
    "\n",
    "# multiprocessing\n",
    "multi_num = 8\n",
    "p = Pool(multi_num)\n",
    "p.map(wrapper, zip_list)\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(wsi_id, weight_path=WEIGHT_PATH, crop_size=CROP_SIZE, overlap=OVERLAP):\n",
    "    \"\"\"\n",
    "    Predict the cropped image.\n",
    "    Path of the predicted image.\n",
    "        predict_image/{crop_size}_{overlap}/{train or test}/{wsi_id}/{left top x of WSI}_{left top y of WSI}.png\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    wsi_id : int\n",
    "    weight_path : str\n",
    "    crop_size : int\n",
    "        Image size of the cropped images.\n",
    "    overlap : int\n",
    "        Number of pixels that overlap with adjacent cropped images.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Nothing.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(\"crop_image/{}_{}/{}\".format(crop_size, overlap, wsi_id)):\n",
    "        print(\"crop_image/{}_{}/{} does not exist!!\".format(crop_size, overlap, wsi_id))\n",
    "        return 0\n",
    "\n",
    "    crop_list = glob.glob(\"crop_image/{}_{}/{}/*\".format(crop_size, overlap, wsi_id))\n",
    "    model = unet((crop_size, crop_size, 3))\n",
    "    \n",
    "    if os.path.exists(\"{}/unet.h5\".format(weight_dir)):\n",
    "        model.load_weights(\"{}/unet.h5\".format(weight_dir))\n",
    "    else:\n",
    "        print(\"Weight path is not correct.\")\n",
    "        return 0\n",
    "\n",
    "    if wsi_id in test_wsi_ids:\n",
    "        save_dir = \"predict_image/{}_{}/test/{}\".format(crop_size, overlap, wsi_id)\n",
    "    else:\n",
    "        save_dir = \"predict_image/{}_{}/train/{}\".format(crop_size, overlap, wsi_id)\n",
    "    \n",
    "    print(\"Now processing wsi id : {}\".format(wsi_id))\n",
    "    \n",
    "    if os.path.exists(save_dir):\n",
    "        shutil.rmtree(save_dir)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    for crop_path in crop_list:\n",
    "        img = cv2.imread(crop_path)\n",
    "        l = re.split(\"/|_|\\.\", crop_path)\n",
    "        location = (int(l[-3]), int(l[-2]))\n",
    "        image_size = img.shape[:2]\n",
    "        img_conv = img[:,:,::-1] / 255\n",
    "        img_conv = np.reshape(img_conv,(1,)+img_conv.shape)\n",
    "        \n",
    "        unet_pred = model.predict_on_batch(img_conv)\n",
    "        unet_pred = np.squeeze(unet_pred)\n",
    "        unet_pred = np.array(unet_pred*255, dtype=np.uint8)\n",
    "      \n",
    "        cv2.imwrite(\"{}/{}_{}.png\".format(save_dir, location[0], location[1]), unet_pred[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "slide_list = glob.glob(\"MITOS_WSI_CMC/WSI/*.svs\")\n",
    "\n",
    "for slide_path in slide_list:\n",
    "    filename = slide_path.split(\"/\")[-1]\n",
    "    filedata = file_df[file_df[\"filename\"]==filename]\n",
    "    wsi_id = filedata.iat[0, 0]\n",
    "    predict(wsi_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold and result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(wsi_id, th, crop_size=CROP_SIZE, overlap=OVERLAP, test_mode=True):\n",
    "    \"\"\"\n",
    "    Extract only the mitotic channel from the U-Net output, binarize it, \n",
    "    perform blob detection, and write the detected coordinates to a text file.\n",
    "    The text file contains a space-delimited list of detected point coordinates in x,y format.\n",
    "    Example : 23,543 650,938 759,980 ... x,y ...\n",
    "    \n",
    "    Path of the text file.\n",
    "        threshold/{crop_size}_{overlap}/{th}/{train or test}/{wsi_id}.txt\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    wsi_id : int\n",
    "    th : int\n",
    "        Threshold value used in the binarization process, ranging from 0 to 255.\n",
    "    crop_size : int\n",
    "        Image size of the cropped images.\n",
    "    overlap : int\n",
    "        Number of pixels that overlap with adjacent cropped images.\n",
    "    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Nothing.\n",
    "    \"\"\"\n",
    "    if test_mode==True:\n",
    "        read_dir = \"predict_image/{}_{}/test/{}\".format(crop_size, overlap, wsi_id)\n",
    "        save_dir = \"threshold/{}_{}/{}/test\".format(crop_size, overlap, th)\n",
    "    else:\n",
    "        read_dir = \"predict_image/{}_{}/train/{}\".format(crop_size, overlap, wsi_id)\n",
    "        save_dir = \"threshold/{}_{}/{}/train\".format(crop_size, overlap, th)\n",
    "\n",
    "    if not os.path.exists(read_dir):\n",
    "        #print(\"{} does not exist!!\".format(read_dir))\n",
    "        return 0\n",
    "    else:\n",
    "        pre_list = glob.glob(\"{}/*\".format(read_dir))    \n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    if os.path.exists(\"{}/{}.txt\".format(save_dir, wsi_id)):\n",
    "        os.remove(\"{}/{}.txt\".format(save_dir, wsi_id))\n",
    "        \n",
    "    with open(\"{}/{}.txt\".format(save_dir, wsi_id), mode='a') as f:\n",
    "        for pre_path in pre_list:\n",
    "            pre = cv2.imread(pre_path)\n",
    "            l = re.split(\"/|_|\\.\", pre_path)\n",
    "            location = (int(l[-3]), int(l[-2]))\n",
    "            ret, img_th = cv2.threshold(pre[overlap:-overlap, overlap:-overlap, 2], th, 255, cv2.THRESH_BINARY)\n",
    "            label = cv2.connectedComponentsWithStats(img_th)\n",
    "            n = label[0] - 1\n",
    "            center_pre = np.delete(label[3], 0, 0)\n",
    "\n",
    "            for x,y in center_pre:\n",
    "                f.write(\"{},{} \".format(int(x+overlap+location[0]), int(y+overlap+location[1]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "th_list = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180 ,190, 200, 210, 220, 230, 240, 250]\n",
    "slide_list = glob.glob(\"MITOS_WSI_CMC/WSI/*.svs\")\n",
    "test_mode = True  # True at time of testing\n",
    "for th in th_list:\n",
    "    zip_list = []\n",
    "    print(\"Now processing threshold : {}\".format(th))\n",
    "    for slide_path in slide_list:\n",
    "        filename = slide_path.split(\"/\")[-1]\n",
    "        filedata = file_df[file_df[\"filename\"]==filename]\n",
    "        wsi_id = filedata.iat[0, 0]\n",
    "        zip_list.append([wsi_id, th, test_mode])\n",
    "\n",
    "    # To give multiple arguments\n",
    "    def wrapper(args):\n",
    "        return threshold(*args) \n",
    "\n",
    "    # multiprocessing\n",
    "    multi_num = 8\n",
    "    p = Pool(multi_num)\n",
    "    p.map(wrapper, zip_list)\n",
    "    p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "True positive (TP) is defined as the prediction point is within a 25 pixel radius of the annotated point.\n",
    "\n",
    "False negative (FN) is defined when there is no prediction point within a 25 pixel radius of the annotated point.\n",
    "\n",
    "False positive (FP) is defined when there is no annotated point within a 25 pixel radius of the prediction point.\n",
    "\n",
    "Precision indicates the accuracy of the prediction.\n",
    "\n",
    "$Precision=\\frac{TP}{TP + FP}$  \n",
    "\n",
    "Recall indicates how well the GT were detected without omission.  \n",
    "\n",
    "$Recall=\\frac{TP}{TP + FN}$  \n",
    "\n",
    "If we detect only easily distinguishable objects, Precision will increase, but Recall will decrease. Conversely, if the number of predictions increases, Recall increases but Precision decreases. F1 score is a comprehensive index that evaluates Recall and Precision.  \n",
    "\n",
    "$F1 score=\\frac{2 \\times Precision \\times Recall}{Precision + Recall}$\n",
    "\n",
    "Evaluate the performance of the model using F1score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(xy_list, radius: float = 25):\n",
    "    \n",
    "    X = xy_list\n",
    "    tree = KDTree(X)\n",
    "\n",
    "    radius=25\n",
    "    ind = tree.query_radius(X, r=radius)\n",
    "    dup_idx = []\n",
    "    for i in ind:\n",
    "        if len(i)>1:\n",
    "            for j in i[1:]:\n",
    "                if not j in dup_idx:\n",
    "                    dup_idx.append(j)\n",
    "    for i in reversed(sorted(dup_idx)):\n",
    "        xy_list.pop(i)\n",
    "\n",
    "    return xy_list\n",
    "\n",
    "\n",
    "def _F1_core(centers_DB : np.ndarray, xy_list):\n",
    "    center_x = xy_list[:, 0] \n",
    "    center_y = xy_list[:, 1]\n",
    "    \n",
    "    isDet = np.zeros(xy_list.shape[0]+centers_DB.shape[0])\n",
    "    isDet[0:xy_list.shape[0]]=1 # mark as detection, rest ist GT\n",
    "\n",
    "    if (centers_DB.shape[0]>0):\n",
    "        center_x = np.hstack((center_x, centers_DB[:,0]))\n",
    "        center_y = np.hstack((center_y, centers_DB[:,1]))\n",
    "        \n",
    "    # set up kdtree \n",
    "    X = np.dstack((center_x, center_y))[0]\n",
    "\n",
    "    if (X.shape[0]==0):\n",
    "        return 0,0,0,0\n",
    "\n",
    "    try:\n",
    "        tree = KDTree(X)\n",
    "    except:\n",
    "        print('Shapes of X: ',X.shape)\n",
    "        raise Error()\n",
    "\n",
    "    radius = 25\n",
    "    ind = tree.query_radius(X, r=radius)\n",
    "\n",
    "    annotationWasDetected = {x: 0 for x in np.where(isDet==0)[0]}\n",
    "    DetectionMatchesAnnotation = {x: 0 for x in np.where(isDet==1)[0]}\n",
    "\n",
    "    # check: already used results\n",
    "    alreadyused=[]\n",
    "    for i in ind:\n",
    "        if len(i)==0:\n",
    "            continue\n",
    "        if np.any(isDet[i]) and np.any(isDet[i]==0):\n",
    "            # at least 1 detection and 1 non-detection --> count all as hits\n",
    "            for j in range(len(i)):\n",
    "                if not isDet[i][j]: # is annotation, that was detected\n",
    "                    if i[j] not in annotationWasDetected:\n",
    "                        print('Missing key ',j, 'in annotationWasDetected')\n",
    "                        raise ValueError('Ijks')\n",
    "                    annotationWasDetected[i[j]] = 1\n",
    "                else:\n",
    "                    if i[j] not in DetectionMatchesAnnotation:\n",
    "                        print('Missing key ',j, 'in DetectionMatchesAnnotation')\n",
    "                        raise ValueError('Ijks')\n",
    "\n",
    "                    DetectionMatchesAnnotation[i[j]] = 1\n",
    "\n",
    "    #TP = np.sum([annotationWasDetected[x]==1 for x in annotationWasDetected.keys()])\n",
    "    TP = [X[x] for x, y in annotationWasDetected.items() if y==1]\n",
    "    #FN = np.sum([annotationWasDetected[x]==0 for x in annotationWasDetected.keys()])\n",
    "    FN = [X[x] for x, y in annotationWasDetected.items() if y==0]\n",
    "    #FP = np.sum([DetectionMatchesAnnotation[x]==0 for x in DetectionMatchesAnnotation.keys()])\n",
    "    FP = [X[x] for x, y in DetectionMatchesAnnotation.items() if y==0]\n",
    "    #F1 = 2*TP/(2*TP + FP + FN)\n",
    "\n",
    "    #return F1, TP, FP, FN\n",
    "    return TP, FP, FN\n",
    "\n",
    "\n",
    "def calculate_F1(result_dir=None, databasefile='MITOS_WSI_CMC/databases/MITOS_WSI_CMC_CODAEL_TR_ROI.sqlite', hotclass=2):\n",
    "    info = result_dir.split(\"/\")[1]\n",
    "    th = result_dir.split(\"/\")[2]\n",
    "    DB = sqlite3.connect(databasefile)\n",
    "    label_df = pd.read_sql('SELECT * FROM Annotations', DB)\n",
    "    \n",
    "    mitosis_df = label_df[label_df[\"agreedClass\"]==hotclass]\n",
    "    coordinates_df = pd.read_sql('SELECT * FROM Annotations_coordinates', DB)\n",
    "\n",
    "    if result_dir is None:\n",
    "        raise ValueError('At least one of resfile/result_boxes must be given')\n",
    "        return 0\n",
    "    else:\n",
    "        result_list = glob.glob(\"{}/*\".format(result_dir))        \n",
    "\n",
    "    sTP, sFN, sFP = 0,0,0\n",
    "    F1dict = dict()\n",
    "    \n",
    "    for result_path in result_list:\n",
    "        filename = result_path.split(\"/\")[-1]\n",
    "        wsi_id = int(filename.split(\".\")[0])\n",
    "        cells = coordinates_df[(coordinates_df[\"slide\"]==wsi_id)]\n",
    "\n",
    "        annoList=[]\n",
    "        for _, row in cells.iterrows():\n",
    "            uid = int(row.annoId)\n",
    "            if not mitosis_df[(mitosis_df[\"uid\"]==uid)].empty:\n",
    "                x = int(row.coordinateX)\n",
    "                y = int(row.coordinateY)\n",
    "                annoList.append([x, y])\n",
    "\n",
    "        centers_DB = np.array(annoList)\n",
    "        \n",
    "        xy_list=[]\n",
    "        with open(result_path, 'r') as f:\n",
    "            for idx, line in enumerate(f):\n",
    "                line_split = line.strip().split(' ')\n",
    "                for i in line_split:\n",
    "                    split = i.split(',')\n",
    "                    x = int(split[0])\n",
    "                    y = int(split[1])\n",
    "                    xy_list.append([x, y])\n",
    "\n",
    "        if len(xy_list)>0:   \n",
    "            xy_list = nms(xy_list)\n",
    "            xy_list = np.array(xy_list)\n",
    "\n",
    "            TP, FP, FN = _F1_core(centers_DB, xy_list)\n",
    "        else:\n",
    "            TP, FP, FN = [], [], annoList\n",
    "            \n",
    "        save_dir = \"result/{}/{}/{}\".format(result_path.split(\"/\")[-4], result_path.split(\"/\")[-3], result_path.split(\"/\")[-2])  \n",
    "\n",
    "        # Save the coordinates of the points determined to be TP, FP, and FN.\n",
    "        if os.path.exists(\"{}/{}_TP.txt\".format(save_dir, wsi_id)):\n",
    "            os.remove(\"{}/{}_TP.txt\".format(save_dir, wsi_id))\n",
    "        if os.path.exists(\"{}/{}_FP.txt\".format(save_dir, wsi_id)):\n",
    "            os.remove(\"{}/{}_FP.txt\".format(save_dir, wsi_id))\n",
    "        if os.path.exists(\"{}/{}_FN.txt\".format(save_dir, wsi_id)):\n",
    "            os.remove(\"{}/{}_FN.txt\".format(save_dir, wsi_id))\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        with open(\"{}/{}_TP.txt\".format(save_dir, wsi_id), mode='a') as f:\n",
    "            for tp in TP:\n",
    "                f.write(\"{},{} \".format(tp[0], tp[1]))\n",
    "\n",
    "        with open(\"{}/{}_FP.txt\".format(save_dir, wsi_id), mode='a') as f:\n",
    "            for fp in FP:\n",
    "                f.write(\"{},{} \".format(fp[0], fp[1]))\n",
    "                \n",
    "        with open(\"{}/{}_FN.txt\".format(save_dir, wsi_id), mode='a') as f:\n",
    "            for fn in FN:\n",
    "                f.write(\"{},{} \".format(fn[0], fn[1]))\n",
    "                \n",
    "        R, P = 0, 0\n",
    "        if (len(TP) + len(FP))!=0:\n",
    "            R = len(TP)/(len(TP) + len(FN))\n",
    "            P = len(TP)/(len(TP) + len(FP))\n",
    "        if (R+P)!=0:\n",
    "            F1 = 2*R*P/(R+P)\n",
    "        else:\n",
    "            F1 = \"NaN\"\n",
    "\n",
    "        print(\"wsi_id:\", wsi_id, 'TP:', len(TP), 'FP:', len(FP), 'FN:', len(FN), 'F1:', F1)\n",
    "\n",
    "        sTP+=len(TP)\n",
    "        sFP+=len(FP)\n",
    "        sFN+=len(FN)\n",
    "        F1dict[wsi_id]=F1\n",
    "        \n",
    "    print('Overall: ')\n",
    "    sRecall = sTP/(sTP + sFN)\n",
    "    if (sTP + sFP)!=0:\n",
    "        sPrecision = sTP/(sTP + sFP)\n",
    "    else:\n",
    "        sPrecision = 1\n",
    "    sF1 = 2*sTP/(2*sTP + sFP + sFN)\n",
    "    print(\"TP:\", sTP, \"FP:\", sFP, \"FN:\", sFN, \"R:\", sRecall, \"P:\", sPrecision, \"F1:\", sF1)\n",
    "\n",
    "    return th, sPrecision, sRecall, sF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_list = glob.glob(\"threshold/2048_64/*/train\")\n",
    "\n",
    "multi_num = 8\n",
    "p = Pool(multi_num)\n",
    "d = p.map(calculate_F1, dir_list)\n",
    "print(d)\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted_d = sorted(d, key=lambda x:(int(x[0]), int(x[1])))\n",
    "df_train = pd.DataFrame(sorted_d)\n",
    "df_train.columns = [\"Threshold\", \"Precision\", \"Recall\", \"F1score\"]\n",
    "#df.to_csv(\"result.csv\")\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(df_train[\"Threshold\"], df_train[\"Precision\"], label=\"Precision\")\n",
    "plt.plot(df_train[\"Threshold\"], df_train[\"Recall\"], label=\"Recall\")\n",
    "plt.plot(df_train[\"Threshold\"], df_train[\"F1score\"], label=\"F1score\")\n",
    "plt.xlabel(\"Threshold (0~255)\")\n",
    "plt.ylabel(\"Value (0~1)\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_list = glob.glob(\"threshold/2048_64/*/test\")\n",
    "\n",
    "multi_num = 8\n",
    "p = Pool(multi_num)\n",
    "d = p.map(calculate_F1, dir_list)\n",
    "print(d)\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted_d = sorted(d, key=lambda x:(int(x[0]), int(x[1])))\n",
    "df_test = pd.DataFrame(sorted_d)\n",
    "df_test.columns = [\"Threshold\", \"Precision\", \"Recall\", \"F1score\"]\n",
    "#df.to_csv(\"result.csv\")\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(df_test[\"Threshold\"], df_test[\"Precision\"], label=\"Precision\")\n",
    "plt.plot(df_test[\"Threshold\"], df_test[\"Recall\"], label=\"Recall\")\n",
    "plt.plot(df_test[\"Threshold\"], df_test[\"F1score\"], label=\"F1score\")\n",
    "plt.xlabel(\"Threshold (0~255)\")\n",
    "plt.ylabel(\"Value (0~1)\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(df_train[\"Threshold\"], df_train[\"F1score\"], label=\"train\")\n",
    "plt.plot(df_test[\"Threshold\"], df_test[\"F1score\"], label=\"test\")\n",
    "plt.xlabel(\"Threshold (0~255)\")\n",
    "plt.ylabel(\"F1score (0~1)\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tf-keras)",
   "language": "python",
   "name": "conda_tf-keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
